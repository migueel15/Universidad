#   if (!length(elems)) list() else
#     elems %>% imap(~map(comb(elems[-1:-.y], n - 1), c, .x)) %>% reduce(c)
# }
##############################################################
# Ejemplos de manejar conjuntos (sucesos) en R
##############################################################
A <- vari(letters[1:5], 2)
B <- vari(letters[3:7], 2)
union(A, B)
intersect(A, B)
setdiff(A, B)
setequal(A, B)
##############################################################
# Ejemplos de c�lculo de cantidades combinatorias
##############################################################
# Combinaciones de 10 elementos tomados de 3 en 3
choose(10, 3)
# Combinaciones de 10 elementos tomados de 3 en 3 con Repetici�n
choose(10 + 3 - 1, 3)
# Variaciones de 10 elementos tomados de 3 en 3
factorial(3) * choose(10, 3)
# Variaciones de 10 elementos tomados de 3 en 3 con Repetici�n
10 ^ 3
# Para n�meros muy grandes, son interesantes lchoose y lfactorial
# Calcula logaritmos de las cantidades
lfactorial(1000)
lchoose(10000, 5000)
##############################################################
# Ejemplo: Generar una baraja espa�ola y extraer dos cartas ordenadas
##############################################################
cartas <- map(c("O", "C", "B", "E"),str_c, 1:10) %>% reduce(c)
vari(cartas, 2)
##############################################################
# Ejemplo: Una urna con 7 bolas blancas y 5 rojas
##############################################################
urna <- map2(c("B", "R"), list(1:7, 1:5), str_c) %>% reduce(c)
# Extraemos dos bolas al mismo tiempo
extr <- comb(urna, 2)
# Nos quedamos con todas las extraciones d�nde las dos bolas son blancas
extB <- extr %>% keep(~all(startsWith(., "B")))
# Nos quedamos con todas las extraciones d�nde las dos bolas son rojas
extR <- extr %>% keep(~all(startsWith(., "R")))
# Extracciones con las dos bolas son iguales
extEq <- union(extB, extR)
# Como las extracciones son equiprobables, podemos calcular la probabilidad de extraer dos bolas iguales
#  dividiendo casos favorables por vasos posibles.
length(extEq) / length(extr)
##############################################################
# M�todos estad�sticos para la computaci�n
# Escuela T�cnica Superior de Ingenier�a Inform�tica.
# Universidad de M�laga. Curso 2020 / 21
# Tema 4. Probabilidad
##############################################################
library(tidyverse)
##############################################################
# M�todos estad�sticos para la computaci�n
# Escuela T�cnica Superior de Ingenier�a Inform�tica.
# Universidad de M�laga. Curso 2020 / 21
# Tema 4. Probabilidad
##############################################################
library(tidyverse)
1.21+1.63
2.84/2
1.21+1.63
2.84/2
20000000/1000
combn(20000000,1000)
(20000000!)
factorial(20000000)
factorial(20000000)/(factorial(1000))
factorial(8)/factorial
factorial(8)/factorial(6)
qnorm(0.95)
qnorm(0.99)
qnorm(0.925)
qnorm(0.975)
qnorm(.975)
notaPOO <- function(n1,n2,n3){
t1 <- 0.2*n1
t2 <- 0.2*n2
t3 <- (10-(t1+t2)/10)*n3
t1+t2+t3
}
notaPOO(5,5,5)
notaPOO(8.8,10,5)
t1
notaPOO <- function(n1,n2,n3){
t1 <- 0.2*n1
t2 <- 0.2*n2
t3 <- (10-(t1+t2)/10)*n3
t1
}
notaPOO(5,5,5)
notaPOO(8.8,5,5)
notaPOO <- function(n1,n2,n3){
t1 <- 0.2*n1
t2 <- 0.2*n2
t3 <- (10-(t1+t2)/10)*n3
t1+t2+t3
}
notaPOO <- function(n1,n2,n3){
t1 <- 0.2*n1
t2 <- 0.2*n2
t3 <- ((10-(t1+t2))/10)*n3
t1+t2+t3
}
notaPOO(5,5,5)
notaPOO(8.8,10,5)
notaPOO(8.8,10,1)
notaPOO(8.8,10,2)
notaPOO(8.8,10,7)
notaPOO(8.8,10,9)
notaPOO(8.8,10,10)
notaPOO(10,10,10)
notaPOO(8.8,10,6)
notaPOO(8.8,10,4)
notaPOO(8.8,10,3)
notaPOO(8.8,10,8)
notaPOO(8.8,10,9)
median(c(6.22,5.5,5.9,8,8.75))
median(c(6.22,5.5,5.9,8,8.75))
median(c(6.22,5.5,5.9,8,8.75,8,8,7,8,9))
median(c(6.22,5.5,5.9,8,8.75,8,8,9,8,9))
mean(c(6.22,5.5,5.9,8,8.75))
mean(c(6.22,5.5,5.9,8,8.75,7,8,8,7,9))
mean(c(6.22,5.5,5.9,8,8.75,7,8,8,7,9,8,8,9))
mean(c(6.22,5.5,5.9,8,8.75,7,8,8,7,9,8,9,9))
notaPOO(8.8,10,1:10)
##############################################################
# M�todos estad�sticos para la computaci�n
# Escuela T�cnica Superior de Ingenier�a Inform�tica.
# Universidad de M�laga. Curso 2020 / 21
# Tema 6. Inferencia estad�stica
##############################################################
library(tidyverse)
n <- 1000
# Normal
qnorm(.975)
qnorm(.025)
##############################################################
# Intervalos de confianza de una normal
##############################################################
m <- 175
s <- 10
n <- 1000
# Intervalos de la media con la t de student y con la normal al 95%
# Vemos que son casi iguales.
# El correcto es el de la t de student.
# Usar la normal es una aproximaci�n siempre
e1 <- qt(.975, n - 1) * s / sqrt(n)
e2 <- qnorm(.975) * s / sqrt(n)
m + c(-e1, e1)
m + c(-e2, e2)
# intervalo al 99%
e <- qt(.995, n - 1) * s / sqrt(n)
m + c(-e, e)
# Intervalo de confianza de la varianza al 95%
(n-1)*s^2/qchisq(.025, n-1)
(n-1)*s^2/qchisq(.975, n-1)
# Intervalo de la desviaci�n t�pica
sqrt((n-1)*s^2/qchisq(c(.975, .025), n-1))
# TODO Cae!
# Si nos dan la desviaci�n t�pica y hay que calcular la cuasi-desviaci�n t�pica
m <- 170
sn <- 11
n <- 1000
s <- sqrt( n / (n - 1)) * sn
s
# Funciones para facilitar el c�lcul
# Varianzas iguales
sp <- function(nA, sA, nB, sB) sqrt(((nA-1) * sA^2 + (nB-1) * sB^2) / (nA + nB - 2))
ff <- function(n1, s1, n2, s2) round( (s1^2 / n1 + s2^2 / n2) ^ 2 /
((s1^2 / n1) ^ 2 / (n1 + 1) + (s2^2 / n2) ^ 2 / (n2 + 1)) - 2 )
ef1 <- function(nivSign, n1, s1, n2, s2) {
qt(1 - nivSign / 2, n1 + n2 - 2) * sp(n1, s1, n2, s2) * sqrt(1 / n1 + 1 / n2) }
ef2 <- function(nivSign, n1, s1, n2, s2) {
qt(1 - nivSign / 2, ff(n1, s1, n2, s2)) * sqrt(s1 ^ 2 / n1 + s2 ^ 2 / n2) }
# Intervalo de confianza de la diferencia de medias
# nivel de confianza de un 95%
f <- ff(n1, s1, n2, s2)
##############################################################
# Intervalos de confianza de la media
##############################################################
# Medimos 100 espa�oles y miden de media 175, con quasidesv tipica 10
m1 <- 175
s1 <- 10
n1 <- 100
# Medimos 100 suecos y miden de media 177, con quasidesv tipica 9
m2 <- 177
s2 <- 9
n2 <- 100
sp <- function(nA, sA, nB, sB) sqrt(((nA-1) * sA^2 + (nB-1) * sB^2) / (nA + nB - 2))
ff <- function(n1, s1, n2, s2) round( (s1^2 / n1 + s2^2 / n2) ^ 2 /
((s1^2 / n1) ^ 2 / (n1 + 1) + (s2^2 / n2) ^ 2 / (n2 + 1)) - 2 )
ef1 <- function(nivSign, n1, s1, n2, s2) {
qt(1 - nivSign / 2, n1 + n2 - 2) * sp(n1, s1, n2, s2) * sqrt(1 / n1 + 1 / n2) }
ef2 <- function(nivSign, n1, s1, n2, s2) {
qt(1 - nivSign / 2, ff(n1, s1, n2, s2)) * sqrt(s1 ^ 2 / n1 + s2 ^ 2 / n2) }
# Intervalo de confianza de la diferencia de medias
# nivel de confianza de un 95%
f <- ff(n1, s1, n2, s2)
e95 <- ef2(.05, n1, s1, n2, s2)
e95
m2 - m1 + c(-e95, e95)
# nivel de confianza de un 90%
e90 <- ef2(.1, n1, s1, n2, s2)
m2 - m1 + c(-e90, e90)
# nivel de confianza de un 80%
e80 <- ef2(.2, n1, s1, n2, s2)
m2 - m1 + c(-e80, e80)
e95n <- qnorm(.975) * sqrt(s1^2 / n1 + s2^2 / n2)
##############################################################
# Contrastes no param�tricos
##############################################################
# Ejemplo tirada de dado
xx <- sample(1:6, 600, replace=T)
table(xx)
# frecuencia
oo <- as.vector(table(xx))
ee <- rep(100, 6)
oo
ee
# Estad�stico de contraste: (algo as� como tama�o del error)
eC <- sum ((oo - ee) ^ 2 / ee)
eC
##############################################################
# Contrastes no param�tricos
##############################################################
# Ejemplo tirada de dado
xx <- sample(1:6, 600, replace=T)
table(xx)
# frecuencia
oo <- as.vector(table(xx))
ee <- rep(100, 6)
# Estad�stico de contraste: (algo as� como tama�o del error)
eC <- sum ((oo - ee) ^ 2 / ee)
# Forma alternativa de calcularlo
sum(oo^2 / ee) - sum(oo)
# p-value del test no param�trico
# Nos dice la probabilidad de que ocurra lo que ha ocurrido si nuestra hip�tesis es cierta
#  (en este caso, que sea una distribuci�n uniforme)
# Si es un valor muy bajo, deber�amos descartar nuestra hip�tesis.
1 - pchisq(eC, 5)
oo <- c(125, 75, 125, 75, 125, 75)
ee <- rep(100, 6)
# Estad�stico de contraste: (algo as� como tama�o del error)
eC <- sum ((oo - ee) ^ 2 / ee)
eC
# p-value
1 - pchisq(eC, 5)
# Como hay 5 grados de libertad, hay que comparar con esto:
qchisq(.95, 5)
# Forma alternativa de calcularlo
sum(oo^2 / ee) - sum(oo)
# p-value
1 - pchisq(eC, 5)
eC
oo <- c(125, 5, 125, 75, 195, 75)
ee <- rep(100, 6)
# Estad�stico de contraste: (algo as� como tama�o del error)
eC <- sum ((oo - ee) ^ 2 / ee)
eC
oo <- c(125, 75, 125, 75, 125, 75)
ee <- rep(100, 6)
# Estad�stico de contraste: (algo as� como tama�o del error)
eC <- sum ((oo - ee) ^ 2 / ee)
eC
# p-value
1 - pchisq(eC, 5)
##############################################################
# Ejemplo diapositiva 40
##############################################################
oo <- matrix(c(198, 28, 62, 39, 6, 12, 105, 15, 35), byrow=T, ncol=3)
rf <- rowSums(oo) / sum(oo)
cf <- colSums(oo) / sum(oo)
f
rf
cf
o
oo
ee <- matrix(rep(cf, 3) * rep(rf, rep(3, 3)), byrow=T, ncol=3) * sum(oo)
eC <- sum ((oo - ee) ^ 2 / ee)
eC
# p-value
1 - pchisq(eC, 4)
##############################################################
# Ejemplo diapositiva 40
##############################################################
oo <- matrix(c(198, 28, 62, 39, 6, 12, 105, 15, 35), byrow=T, ncol=3)
rf <- rowSums(oo) / sum(oo)
cf <- colSums(oo) / sum(oo)
ee <- matrix(rep(cf, 3) * rep(rf, rep(3, 3)), byrow=T, ncol=3) * sum(oo)
eC <- sum ((oo - ee) ^ 2 / ee)
eC
qchisq(.95, 4)
qchisq(.05, 4)
pchisq(eC, 4)
##############################################################
# Ejemplo diapositiva 34 (Contraste Poisson)
##############################################################
xx <- 0:6
oo <- c(200, 220, 150, 68, 25, 10, 4)
lambda <- sum(xx * oo) / sum(oo)
ee <- c(dpois(0:5, lambda), 1 - ppois(5, lambda)) * sum(oo)
ooA <- c(oo[1:5], oo[6] + oo[7])
eeA <- c(ee[1:5], ee[6] + ee[7])
est <- sum ((ooA - eeA) ^ 2 / eeA)
qchisq(.95, 4)
# p-value
1 - pchisq(est, 4)
pchisq(est, 4)
oo <- c(125, 75, 125, 75, 125, 75)
ee <- rep(100, 6)
# Estad�stico de contraste: (algo as� como tama�o del error)
eC <- sum ((oo - ee) ^ 2 / ee)
eC
# p-value
1 - pchisq(eC, 5)
pchisq(eC, 5)
##############################################################
# Contrastes no param�tricos
##############################################################
# Ejemplo tirada de dado
xx <- sample(1:6, 600, replace=T)
table(xx)
# frecuencia
oo <- as.vector(table(xx))
ee <- rep(100, 6)
# Estad�stico de contraste: (algo as� como tama�o del error)
eC <- sum ((oo - ee) ^ 2 / ee)
# Forma alternativa de calcularlo
sum(oo^2 / ee) - sum(oo)
# Como hay 5 grados de libertad, hay que comparar con esto:
qchisq(.95, 5)
# p-value del test no param�trico
# Nos dice la probabilidad de que ocurra lo que ha ocurrido si nuestra hip�tesis es cierta
#  (en este caso, que sea una distribuci�n uniforme)
# Si es un valor muy bajo, deber�amos descartar nuestra hip�tesis.
1 - pchisq(eC, 5)
pchisq(eC, 5)
#añadimos el directorio
setwd("/home/firez/Universidad/Estadistica/Trabajo R/")
#importamos la libreria tidyverse
library(tidyverse)
#añadimos el directorio
setwd("/home/firez/Universidad/Estadistica/Trabajo R/")
#leemos y cargamos el csv y leemos las variables cualitativas como factores
dfTrabajoR <- read_csv("21425.csv.csv",
col_types = cols(.default = col_double(),
sexo = col_factor(),
dietaEsp = col_factor(),
nivEstudios = col_factor(),
nivIngresos = col_factor()
))
#leemos y cargamos el csv y leemos las variables cualitativas como factores
dfTrabajoR <- read_csv("21425.csv",
col_types = cols(.default = col_double(),
sexo = col_factor(),
dietaEsp = col_factor(),
nivEstudios = col_factor(),
nivIngresos = col_factor()
))
#importamos la libreria tidyverse
library(tidyverse)
#añadimos el directorio
setwd("/home/firez/Universidad/Estadistica/Trabajo R/")
#leemos y cargamos el csv y leemos las variables cualitativas como factores
dfTrabajoR <- read_csv("21425.csv",
col_types = cols(.default = col_double(),
sexo = col_factor(),
dietaEsp = col_factor(),
nivEstudios = col_factor(),
nivIngresos = col_factor()
))
#Creamos la columna IMC
IMC <- dfTrabajoR$peso / dfTrabajoR$altura^2
#Se añade la columna IMC al dataset
dfTrabajoR <- mutate(dfTrabajoR, IMC)
#Eliminamos las filas con NA
dfTrabajoR <- na.omit(dfTrabajoR)
View(dfTrabajoR)
#Como solo piden variables numéricas, usaremos keep(is.numeric), y para hacer la media en
#todas, usaremos map_dbl(mean)
medias <- dfTrabajoR%>%keep(is.numeric)%>%map_dbl(mean)
medias
#calculamos la desviación típica
desvtipica <- dfTrabajoR%>%keep(is.numeric)%>%map_dbl(sd)
desvtipica <- desvtipica * sqrt((nrow(dfTrabajoR)-1)/nrow(dfTrabajoR))
desvtipica
#guardamos  las regresiones lineales  unidimensionales
regUnid <- names(dfTrabajoR[3:14])
regUnid
#funcion para calcular el coeficiente de regresion usando un ajuste lineal lm
coefRegresion <- function(df,y,x){
mod <- lm(str_c(y, "~", x), df)
summary(mod)$coefficients[2]
}
#y una para calcular el coeficiente de determinacion usando un ajuste lineal lm
R2 <- function(df, y, x){
mod <- lm(str_c(y, "~", x), df)
summary(mod)$r.squared
}
pendientes <- regUnid%>%map_dbl(coefRegresion, df=dfTrabajoR, y="IMC")
pendientes
coefDet <- regUnid %>%map_dbl(R2, df=dfTrabajoR, y="IMC")
coefDet
#funcion que calcula un ajuste lineal de 2 variables
ajusteLineal <- function(df, y, x){
list(x=x, y=y, mod=lm(str_c(y, "~", x), df))
}
#funcion que crea los graficos y los almacena en una direccion
modDraw <- function(mod){
jpeg(str_c("C:/Users/Salma/Desktop/Universidad/Estadistica/grafos/", mod$x,
".jpeg"))
if(is.numeric(dfTrabajoR[[mod$x]])){
plot(dfTrabajoR[[mod$x]],
dfTrabajoR[[mod$y]], main="Grafica", xlab=mod$y, col="red")
abline(mod$mod, col="blue")
}else{
boxplot(formula=dfTrabajoR[[mod$y]]~dfTrabajoR[[mod$x]], xlab=mod$x, ylab="IMC",
col="red")
}
dev.off()
}
#creamos la funcion que crea los graficos de dispersion con el walk
mods <- regUnid%>%map(~ajusteLineal(dfTrabajoR, "IMC",.))
separarSets <- function(df, p1, p2){
rDf <- 1:nrow(df)
rTrain <- sample(rDf, p1 * length(rDf))
rTemp <- setdiff(rDf, rTrain)
rTest <- sample(rTemp, p2 * length(rDf))
rValid <- setdiff(rTemp, rTest)
list(train = df[rTrain,], test = df[rTest,], valid = df[rValid,])
}
#guardamos en dfs los datos, si peso y altura
dfTrabajoRdatos <- select(dfTrabajoR, -peso, -altura)
dfs <- separarSets(dfTrabajoRdatos, .6, .2)
dfs
#funcion que devuelve el coeficiente de determinacion
calcR2 <- function(df, mod, y){
#error cuadratico medio
MSE <- mean((df[[y]]-predict.lm(mod, df)) ^2)
#varianza
varY <- mean(df[[y]] ^2) - mean(df[[y]]) ^2
#coeficiente de regresion
R2 <- 1 - MSE / varY
#coeficiente de determinacion
aR2 <- 1 - (1 - R2) * (nrow(df) -1) / (nrow(df) - mod$rank)
#muestra con valor y nombre las variables escritas:
tibble (MSE=MSE, varY=varY, R2=R2, aR2=aR2)
}
#funcion de ajuste lineal
linearAdjust <- function(df, y, x){
lm(str_c(y, "~", x), df)
}
#funcion de ajuste lineal que devuelve el coeficiente de determinacion
calcModR2 <- function(dfTrain, dfTest, y, x){
mod <- linearAdjust(dfTrain, y, x)
calcR2(dfTest, mod, y)$aR2
}
varPred <- names(select(dfTrabajoRdatos, -IMC))
varPred
max <- varPred %>% map_dbl(calcModR2, dfTrain=dfs$train, dfTest=dfs$test, y = "IMC")
max
#Guardamos en una nueva variable bestVariable la mejor variable predicha
bestVariable <- varPred[which.max(max)]
bestVariable
#funcion de ajuste lineal que va recibiendo las diferentes variables
linearAdjust <- function(df, y, x){
lm(str_c(y, "~", str_c(x, collapse = "+")), df)
}
#funcion que calcula el mejor de los ajustes
findbest <- function(dfTrain, dfTest, varPos){
bestVars <- character(0)
#va a mejor hasta que no pueda mas, y empieza en 0
aR2 <- 0
repeat{
aR2v <- map_dbl(varPos, ~calcModR2(dfTrain, dfTest, "IMC", c(bestVars, .)))
#se calcula la posicion que tenga el maximo
i <- which.max(aR2v)
#guardamos el aR2 en una nueva variable que sea el maximo
aR2M <- aR2v[i]
#vemos si mejora el R2
if(aR2M <= aR2) break
#dice el valor del aR2 y el nombre de la variable
cat(sprintf("%1.4f %s\n", aR2M, varPos[i]))
#guardamos el maximo
aR2 <- aR2M
#al array de mejores variables la nueva variable
bestVars <- c(bestVars, varPos[i])
#eliminamos la variable añadida
varPos <- varPos[-i]
}
mod <- linearAdjust(dfTrain, "IMC", bestVars)
list(vars=bestVars, mod=mod)
}
findbest(dfTrain=dfs$train, dfTest = dfs$test, varPos = varPred)
#para cada variable su R2 ajustado
aR2v <- varPred %>% map_dbl(calcModR2, dfTrain=dfs$train, dfTest=dfs$test, y="IMC")
#calcula el mejor modelo actualizando la mejor variable
bestMod1 <- findbest(dfs$train, dfs$test, varPred)
bestMod1
calcR2(dfs$valid, bestMod1$mod, "IMC")
dfTrabajoR <- read_csv("eval.csv")
dfTrabajoR["IMC"] <- predict.lm(bestMod1, dfTrabajoR)
bestMod1$mod
dfTrabajoR["IMC"] <- predict.lm(bestMod1$mod, dfTrabajoR)
dfTrabajoR["Peso"] <- dfTrabajoR$IMC*dfTrabajoR$altura^2
View(dfTrabajoRdatos)
dfTrabajoR <- read_csv("eval.csv")
dfTrabajoR["IMC"] <- predict.lm(bestMod1$mod, dfTrabajoR)
dfTrabajoR["Peso"] <- dfTrabajoR$IMC*dfTrabajoR$altura^2
