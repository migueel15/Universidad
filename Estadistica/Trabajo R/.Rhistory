setequal(A, B)
##############################################################
# Ejemplos de c�lculo de cantidades combinatorias
##############################################################
# Combinaciones de 10 elementos tomados de 3 en 3
choose(10, 3)
# Combinaciones de 10 elementos tomados de 3 en 3 con Repetici�n
choose(10 + 3 - 1, 3)
# Variaciones de 10 elementos tomados de 3 en 3
factorial(3) * choose(10, 3)
# Variaciones de 10 elementos tomados de 3 en 3 con Repetici�n
10 ^ 3
# Para n�meros muy grandes, son interesantes lchoose y lfactorial
# Calcula logaritmos de las cantidades
lfactorial(1000)
lchoose(10000, 5000)
##############################################################
# Ejemplo: Generar una baraja espa�ola y extraer dos cartas ordenadas
##############################################################
cartas <- map(c("O", "C", "B", "E"),str_c, 1:10) %>% reduce(c)
vari(cartas, 2)
##############################################################
# Ejemplo: Una urna con 7 bolas blancas y 5 rojas
##############################################################
urna <- map2(c("B", "R"), list(1:7, 1:5), str_c) %>% reduce(c)
# Extraemos dos bolas al mismo tiempo
extr <- comb(urna, 2)
# Nos quedamos con todas las extraciones d�nde las dos bolas son blancas
extB <- extr %>% keep(~all(startsWith(., "B")))
# Nos quedamos con todas las extraciones d�nde las dos bolas son rojas
extR <- extr %>% keep(~all(startsWith(., "R")))
# Extracciones con las dos bolas son iguales
extEq <- union(extB, extR)
# Como las extracciones son equiprobables, podemos calcular la probabilidad de extraer dos bolas iguales
#  dividiendo casos favorables por vasos posibles.
length(extEq) / length(extr)
##############################################################
# M�todos estad�sticos para la computaci�n
# Escuela T�cnica Superior de Ingenier�a Inform�tica.
# Universidad de M�laga. Curso 2020 / 21
# Tema 4. Probabilidad
##############################################################
library(tidyverse)
##############################################################
# Funciones para calcular conjuntos combinatorios
# En pocas l�neas definimos 5 funciones combinatorias
# variaciones, Combinaciones, Variaciones con repetici�n,
#   Combinaciones con repetici�n y Permutaciones
##############################################################
combU <- function(f, elems, n){
if (!n) list(integer(0)) else
if (!length(elems)) list() else
elems %>% imap(~map(combU(f, f(elems, .y), n - 1), c, .x)) %>% reduce(c)
}
vari  <- partial(combU, function(e, i) e[-i])
comb  <- partial(combU, function(e, i) e[-1:-i])
variR <- partial(combU, function(e, i) e)
combR <- partial(combU, function(e, i) e[i:length(e)])
permu <- function(e) vari(e, length(e))
##############################################################
# Si quieres entender como funciona combU, aqu� tienes como ser�a
#   definir dos de las funciones directamente
##############################################################
# variR <- function(elems, n){
#   if (!n) list(integer(0)) else
#   if (!length(elems)) list() else
#     elems %>% map(~map(variR(elems, n - 1), c, .x)) %>% reduce(c)
# }
# comb <- function(elems, n){
#   if (!n) list(integer(0)) else
#   if (!length(elems)) list() else
#     elems %>% imap(~map(comb(elems[-1:-.y], n - 1), c, .x)) %>% reduce(c)
# }
##############################################################
# Ejemplos de manejar conjuntos (sucesos) en R
##############################################################
A <- vari(letters[1:5], 2)
B <- vari(letters[3:7], 2)
union(A, B)
intersect(A, B)
setdiff(A, B)
setequal(A, B)
##############################################################
# Ejemplos de c�lculo de cantidades combinatorias
##############################################################
# Combinaciones de 10 elementos tomados de 3 en 3
choose(10, 3)
# Combinaciones de 10 elementos tomados de 3 en 3 con Repetici�n
choose(10 + 3 - 1, 3)
# Variaciones de 10 elementos tomados de 3 en 3
factorial(3) * choose(10, 3)
# Variaciones de 10 elementos tomados de 3 en 3 con Repetici�n
10 ^ 3
# Para n�meros muy grandes, son interesantes lchoose y lfactorial
# Calcula logaritmos de las cantidades
lfactorial(1000)
lchoose(10000, 5000)
##############################################################
# Ejemplo: Generar una baraja espa�ola y extraer dos cartas ordenadas
##############################################################
cartas <- map(c("O", "C", "B", "E"),str_c, 1:10) %>% reduce(c)
vari(cartas, 2)
##############################################################
# Ejemplo: Una urna con 7 bolas blancas y 5 rojas
##############################################################
urna <- map2(c("B", "R"), list(1:7, 1:5), str_c) %>% reduce(c)
# Extraemos dos bolas al mismo tiempo
extr <- comb(urna, 2)
# Nos quedamos con todas las extraciones d�nde las dos bolas son blancas
extB <- extr %>% keep(~all(startsWith(., "B")))
# Nos quedamos con todas las extraciones d�nde las dos bolas son rojas
extR <- extr %>% keep(~all(startsWith(., "R")))
# Extracciones con las dos bolas son iguales
extEq <- union(extB, extR)
# Como las extracciones son equiprobables, podemos calcular la probabilidad de extraer dos bolas iguales
#  dividiendo casos favorables por vasos posibles.
length(extEq) / length(extr)
##############################################################
# M�todos estad�sticos para la computaci�n
# Escuela T�cnica Superior de Ingenier�a Inform�tica.
# Universidad de M�laga. Curso 2020 / 21
# Tema 4. Probabilidad
##############################################################
library(tidyverse)
##############################################################
# M�todos estad�sticos para la computaci�n
# Escuela T�cnica Superior de Ingenier�a Inform�tica.
# Universidad de M�laga. Curso 2020 / 21
# Tema 4. Probabilidad
##############################################################
library(tidyverse)
1.21+1.63
2.84/2
1.21+1.63
2.84/2
20000000/1000
combn(20000000,1000)
(20000000!)
factorial(20000000)
factorial(20000000)/(factorial(1000))
factorial(8)/factorial
factorial(8)/factorial(6)
qnorm(0.95)
qnorm(0.99)
qnorm(0.925)
qnorm(0.975)
qnorm(.975)
setwd("~/Universidad/Estadistica/Trabajo R")
library(tidyverse)
library(readr)
library(purrr)
data <- read_csv("21425.csv", col_types=cols(.default=col_double(), sexo=col_factor(),
dietaEsp=col_factor(), nivEstPad=col_factor(),
nivEstudios=col_factor(), nivIngresos=col_factor()))
data$IMC <- data$peso/data$altura^2
data <- na.omit(data)
dfNumerico <- keep(data,is.numeric)
medias <- map_dbl(dfNumerico, mean)
desvTipicas <- dfNumerico %>%
summarise_all(function(x) sqrt(mean(x^2) - mean(x)^2)) %>%
map_dbl(function(x) x)
namesRegresiones <- names(data[4:15])
coefRegresion <- function(df,y,x){
modelo <- lm(y ~ x, df)
summary(modelo)$coefficients[2]
}
calcR2 <- function(df,y,x){
modelo <- lm(y ~ x, df)
summary(modelo)$r.squared
}
coeficientes <- map_dbl(namesRegresiones, ~ coefRegresion(data,data$IMC, data[[.]]))
valoresR2 <- map_dbl(namesRegresiones, ~ calcR2(data,data$IMC, data[[.]]))
linearAdjust <- function(df, y, x) {
list(x=x, y=y, mod=lm(str_c(y, "~", x), df))
}
library(tidyverse)
library(readr)
library(purrr)
data <- read_csv("21425.csv", col_types=cols(.default=col_double(), sexo=col_factor(),
dietaEsp=col_factor(), nivEstPad=col_factor(),
nivEstudios=col_factor(), nivIngresos=col_factor()))
data$IMC <- data$peso/data$altura^2
data <- na.omit(data)
dfNumerico <- keep(data,is.numeric)
medias <- map_dbl(dfNumerico, mean)
desvTipicas <- dfNumerico %>%
summarise_all(function(x) sqrt(mean(x^2) - mean(x)^2)) %>%
map_dbl(function(x) x)
namesRegresiones <- names(data[4:15])
coefRegresion <- function(df,y,x){
modelo <- lm(y ~ x, df)
summary(modelo)$coefficients[2]
}
calcR2 <- function(df,y,x){
modelo <- lm(y ~ x, df)
summary(modelo)$r.squared
}
coeficientes <- map_dbl(namesRegresiones, ~ coefRegresion(data,data$IMC, data[[.]]))
valoresR2 <- map_dbl(namesRegresiones, ~ calcR2(data,data$IMC, data[[.]]))
linearAdjust <- function(df, y, x) {
list(x=x, y=y, mod=lm(str_c(y, "~", x), df))
}
dibujarModelos <- function(mod) {
jpeg(str_c("./Imagenes/", mod$x, ".jpeg"))
if (is.numeric(data[[mod$x]])) {
plot(data[[mod$x]], data[[mod$y]], xlab=mod$x, ylab=mod$y)
abline(mod$mod, col="red")
}else{
boxplot(formula=data[[mod$y]] ~ data[[mod$x]], xlab=mod$x, ylab=mod$y)
}
dev.off()
}
mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods %>% walk(dibujarModelos)
separarSets <- function(df, p1, p2) {
rDf <- 1:nrow(df)
rTrain <- sample(rDf, p1 * length(rDf))
rResto  <- setdiff(rDf, rTrain)
rTest <- sample(rResto, p2*length(rDf))
rValid <- setdiff(rResto, rTest)
list(train=df[rTrain,], test=df[rTest,], valid=df[rValid,])
}
setsSeparados <- separarSets(data,.6,.2)
encontrarMejorAjuste <- function(dfTrain, dfTest, varPos) {
}
encontrarMejorAjuste(setsSeparados$train, setsSeparados$test, "IMC")
encontrarMejorAjuste <- function(dfTrain, dfTest, varPos) {
}
setsSeparados <- separarSets(data,.6,.2)
separarSets <- function(df, p1, p2) {
rDf <- 1:nrow(df)
rTrain <- sample(rDf, p1 * length(rDf))
rResto  <- setdiff(rDf, rTrain)
rTest <- sample(rResto, p2*length(rDf))
rValid <- setdiff(rResto, rTest)
list(train=df[rTrain,], test=df[rTest,], valid=df[rValid,])
}
library(tidyverse)
library(readr)
library(purrr)
data <- read_csv("21425.csv", col_types=cols(.default=col_double(), sexo=col_factor(),
dietaEsp=col_factor(), nivEstPad=col_factor(),
nivEstudios=col_factor(), nivIngresos=col_factor()))
data$IMC <- data$peso/data$altura^2
data <- na.omit(data)
dfNumerico <- keep(data,is.numeric)
medias <- map_dbl(dfNumerico, mean)
desvTipicas <- dfNumerico %>%
summarise_all(function(x) sqrt(mean(x^2) - mean(x)^2)) %>%
map_dbl(function(x) x)
namesRegresiones <- names(data[4:15])
coefRegresion <- function(df,y,x){
modelo <- lm(y ~ x, df)
summary(modelo)$coefficients[2]
}
calcR2 <- function(df,y,x){
modelo <- lm(y ~ x, df)
summary(modelo)$r.squared
}
coeficientes <- map_dbl(namesRegresiones, ~ coefRegresion(data,data$IMC, data[[.]]))
valoresR2 <- map_dbl(namesRegresiones, ~ calcR2(data,data$IMC, data[[.]]))
linearAdjust <- function(df, y, x) {
list(x=x, y=y, mod=lm(str_c(y, "~", x), df))
}
dibujarModelos <- function(mod) {
jpeg(str_c("./Imagenes/", mod$x, ".jpeg"))
if (is.numeric(data[[mod$x]])) {
plot(data[[mod$x]], data[[mod$y]], xlab=mod$x, ylab=mod$y)
abline(mod$mod, col="red")
}else{
boxplot(formula=data[[mod$y]] ~ data[[mod$x]], xlab=mod$x, ylab=mod$y)
}
dev.off()
}
mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- map_dbl(names(data),~linearAdjust(data, "IMC", .))
mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% map(linearAdjust(data, "IMC", .))
mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% map(print("fa"))
mods <- names(data) %>% map_dbl(print("fa"))
mods <- names(data) %>% map(print("fa"))
mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods
plot(data)
plot(data$altura,data$peso)
sf
f
a
da
plot(data$altura,data$peso)
dibujarModelos()
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% map(~linearAdjust(data, "IMC", ))
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% map(~linearAdjust(data, "IMC"))
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% linearAdjust(data, "IMC"))
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% linearAdjust(data, "IMC")
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% linearAdjust(data, "IMC",.)
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% linearAdjust(data, "IMC",.)
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% linearAdjust(data, "IMC",.)
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% map(~linearAdjust(data, "IMC", ))
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% map(~linearAdjust(dfNumerico, "IMC", .))
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(dfNumerico) %>% map(~linearAdjust(dfNumerico, "IMC", .))
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% map(~linearAdjust(dfNumerico, "IMC", .))
mods %>% walk(dibujarModelos)
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods %>% walk(dibujarModelos)
separarSets <- function(df, p1, p2) {
rDf <- 1:nrow(df)
rTrain <- sample(rDf, p1 * length(rDf))
rResto  <- setdiff(rDf, rTrain)
rTest <- sample(rResto, p2*length(rDf))
rValid <- setdiff(rResto, rTest)
list(train=df[rTrain,], test=df[rTest,], valid=df[rValid,])
}
# Importamos la libreria que utilizaremos para crear un tibble. Este es similar
# a read.csv pero añade nuevas funcionalidades.
library(tidyverse)
library(readr)
library(purrr)
# Para cargar el fichero usamos read_csv dando como parametros el nombre del archivo y col_types. Este último nos permite definir el tipo
# de dato que representa cada columno. En este caso hay algunas columnas que no representan datos numéricos sino que son datos
# cualitativos. A todos estos les pongo la propiedad col_factor(). Por ejemplo sexo representa un factor de dos niveles.
data <- read_csv("21425.csv", col_types=cols(.default=col_double(), sexo=col_factor(),
dietaEsp=col_factor(), nivEstPad=col_factor(),
nivEstudios=col_factor(), nivIngresos=col_factor()))
# Añadimos la columna IMC la cual representa el indice de masa corporal de cada individuo.
data$IMC <- data$peso/data$altura^2
# Eliminamos las filas que contengan algún NA en sus columnas. Este método omite todas las filas con algún NA.
data <- na.omit(data)
# Calculamos la media de todas las columnas numéricas.
# Para ello creamos un nuevo dataframe que filtre aquellas columnas que solo sean numéricas haciendo uso de la funcion keep
# importada de purrr
dfNumerico <- keep(data,is.numeric)
medias <- map_dbl(dfNumerico, mean)
# Calculamos la desviación tipica de cada columna numérica. Para ello partimos del df procesado con datos numéricos.
# "%>%" Nos permite pasar el resultado del calculo anterior a el como parametro al cálculo siguiente.
# De esta forma con el método summarise_all calcula lo definido en la función para todas las columnas del dataframe.
# Esto devuelve un dataframe que convertimos en un vector de resultados utilizando map_dbl y esta funcion específica.
desvTipicas <- dfNumerico %>%
summarise_all(function(x) sqrt(mean(x^2) - mean(x)^2)) %>%
map_dbl(function(x) x)
# Calculamos los coeficientes de regresion y el coeficiente de determinación
# para las 12 regresiones lineales unidimensionales.
namesRegresiones <- names(data[4:15])
# Creo una funcion para calcular los ceficientes de regresión haciendo uso de la función lm y summary para obtener un resumen de
# las principales propiedades.
coefRegresion <- function(df,y,x){
modelo <- lm(y ~ x, df)
summary(modelo)$coefficients[2]
}
# Creo una función para obtener el R2 del modelo.
calcR2 <- function(df,y,x){
modelo <- lm(y ~ x, df)
summary(modelo)$r.squared
}
# Haciendo uso de map_dbl puedo calcular una funcion para cada  elemento de un vector
# siendo este el dado como parametro .x
# Es este caso calculo el coeficiente de regresión para todos los valores del vector
# namesRegresiones y los guardo en un vector llamado coeficientes.
coeficientes <- map_dbl(namesRegresiones, ~ coefRegresion(data,data$IMC, data[[.]]))
# De igual forma calculamos el R2 de cada valor del vector namesRegresiones.
valoresR2 <- map_dbl(namesRegresiones, ~ calcR2(data,data$IMC, data[[.]]))
# Creamos una función que nos devuelva una lista con el nombre de las variables
# "x", "y" y el modelo. esta lista la utilizremos para crear los plots con mayor facilidad
linearAdjust <- function(df, y, x) {
list(x=x, y=y, mod=lm(str_c(y, "~", x), df))
}
# Creamos una función para crear el plot o el boxplot correspondiente y guardarlo
# en la ubicación definida.
# Si el valor del elemento es numérico se realizará un plot. En otro caso un boxplot.
# abline crea una recta en el plot que representa la recta de regresión.
dibujarModelos <- function(mod) {
jpeg(str_c("./Imagenes/", mod$x, ".jpeg"))
if (is.numeric(data[[mod$x]])) {
plot(data[[mod$x]], data[[mod$y]], xlab=mod$x, ylab=mod$y)
abline(mod$mod, col="red")
}else{
boxplot(formula=data[[mod$y]] ~ data[[mod$x]], xlab=mod$x, ylab=mod$y)
}
dev.off()
}
# A continuación utilizamos un map para realizar la funcion linearAdjust a todos
# las columnas del dataframe.
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
# Utilizando el metodo walk para generar los graficos.
mods %>% walk(dibujarModelos)
# Separamos el dataframe en 3 sets distintos. Entrenamiento, test y validacion.
# Para ello creo una función que tome como parametros el dataframe y los porcentajes
# Haciendo uso de sample y setdiff creo muestras del dataframe con la longitud indicada.
# Por ultimo guardo los 3 subsets en una lista.
separarSets <- function(df, p1, p2) {
rDf <- 1:nrow(df)
rTrain <- sample(rDf, p1 * length(rDf))
rResto  <- setdiff(rDf, rTrain)
rTest <- sample(rResto, p2*length(rDf))
rValid <- setdiff(rResto, rTest)
list(train=df[rTrain,], test=df[rTest,], valid=df[rValid,])
}
setsSeparados <- separarSets(data,.6,.2)
# Nuestra función estrella que calcula el mejor ajuste lineal
encontrarMejorAjuste <- function(dfTrain, dfTest, varPos) {
}
encontrarMejorAjuste(setsSeparados$train, setsSeparados$test, "IMC")
# Importamos la libreria que utilizaremos para crear un tibble. Este es similar
# a read.csv pero añade nuevas funcionalidades.
library(tidyverse)
library(readr)
library(purrr)
# Para cargar el fichero usamos read_csv dando como parametros el nombre del archivo y col_types. Este último nos permite definir el tipo
# de dato que representa cada columno. En este caso hay algunas columnas que no representan datos numéricos sino que son datos
# cualitativos. A todos estos les pongo la propiedad col_factor(). Por ejemplo sexo representa un factor de dos niveles.
data <- read_csv("21425.csv", col_types=cols(.default=col_double(), sexo=col_factor(),
dietaEsp=col_factor(), nivEstPad=col_factor(),
nivEstudios=col_factor(), nivIngresos=col_factor()))
# Añadimos la columna IMC la cual representa el indice de masa corporal de cada individuo.
data$IMC <- data$peso/data$altura^2
# Eliminamos las filas que contengan algún NA en sus columnas. Este método omite todas las filas con algún NA.
data <- na.omit(data)
# Calculamos la media de todas las columnas numéricas.
# Para ello creamos un nuevo dataframe que filtre aquellas columnas que solo sean numéricas haciendo uso de la funcion keep
# importada de purrr
dfNumerico <- keep(data,is.numeric)
medias <- map_dbl(dfNumerico, mean)
# Calculamos la desviación tipica de cada columna numérica. Para ello partimos del df procesado con datos numéricos.
# "%>%" Nos permite pasar el resultado del calculo anterior a el como parametro al cálculo siguiente.
# De esta forma con el método summarise_all calcula lo definido en la función para todas las columnas del dataframe.
# Esto devuelve un dataframe que convertimos en un vector de resultados utilizando map_dbl y esta funcion específica.
desvTipicas <- dfNumerico %>%
summarise_all(function(x) sqrt(mean(x^2) - mean(x)^2)) %>%
map_dbl(function(x) x)
# Calculamos los coeficientes de regresion y el coeficiente de determinación
# para las 12 regresiones lineales unidimensionales.
namesRegresiones <- names(data[4:15])
# Creo una funcion para calcular los ceficientes de regresión haciendo uso de la función lm y summary para obtener un resumen de
# las principales propiedades.
coefRegresion <- function(df,y,x){
modelo <- lm(y ~ x, df)
summary(modelo)$coefficients[2]
}
# Creo una función para obtener el R2 del modelo.
calcR2 <- function(df,y,x){
modelo <- lm(y ~ x, df)
summary(modelo)$r.squared
}
# Haciendo uso de map_dbl puedo calcular una funcion para cada  elemento de un vector
# siendo este el dado como parametro .x
# Es este caso calculo el coeficiente de regresión para todos los valores del vector
# namesRegresiones y los guardo en un vector llamado coeficientes.
coeficientes <- map_dbl(namesRegresiones, ~ coefRegresion(data,data$IMC, data[[.]]))
# De igual forma calculamos el R2 de cada valor del vector namesRegresiones.
valoresR2 <- map_dbl(namesRegresiones, ~ calcR2(data,data$IMC, data[[.]]))
# Creamos una función que nos devuelva una lista con el nombre de las variables
# "x", "y" y el modelo. esta lista la utilizremos para crear los plots con mayor facilidad
linearAdjust <- function(df, y, x) {
list(x=x, y=y, mod=lm(str_c(y, "~", x), df))
}
# Creamos una función para crear el plot o el boxplot correspondiente y guardarlo
# en la ubicación definida.
# Si el valor del elemento es numérico se realizará un plot. En otro caso un boxplot.
# abline crea una recta en el plot que representa la recta de regresión.
dibujarModelos <- function(mod) {
jpeg(str_c("./Imagenes/", mod$x, ".jpeg"))
if (is.numeric(data[[mod$x]])) {
plot(data[[mod$x]], data[[mod$y]], xlab=mod$x, ylab=mod$y)
abline(mod$mod, col="red")
}else{
boxplot(formula=data[[mod$y]] ~ data[[mod$x]], xlab=mod$x, ylab=mod$y)
}
dev.off()
}
# A continuación utilizamos un map para realizar la funcion linearAdjust a todos
# las columnas del dataframe.
# mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
mods <- names(data) %>% map(~linearAdjust(data, "IMC", .))
# Utilizando el metodo walk para generar los graficos.
mods %>% walk(dibujarModelos)
# Separamos el dataframe en 3 sets distintos. Entrenamiento, test y validacion.
# Para ello creo una función que tome como parametros el dataframe y los porcentajes
# Haciendo uso de sample y setdiff creo muestras del dataframe con la longitud indicada.
# Por ultimo guardo los 3 subsets en una lista.
separarSets <- function(df, p1, p2) {
rDf <- 1:nrow(df)
rTrain <- sample(rDf, p1 * length(rDf))
rResto  <- setdiff(rDf, rTrain)
rTest <- sample(rResto, p2*length(rDf))
rValid <- setdiff(rResto, rTest)
list(train=df[rTrain,], test=df[rTest,], valid=df[rValid,])
}
setsSeparados <- separarSets(data,.6,.2)
# Nuestra función estrella que calcula el mejor ajuste lineal
encontrarMejorAjuste <- function(dfTrain, dfTest, varPos) {
}
encontrarMejorAjuste(setsSeparados$train, setsSeparados$test, "IMC")
setsSeparados$train
+++-++-
8
